{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2527ec1-4263-4d06-a387-090fd763a329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def create_yolo_dataset(folder_path: str):\n",
    "    \"\"\"\n",
    "    Creates train.txt, test.txt, val.txt, and dataset.yaml inside `folder_path`\n",
    "    based on PNG images in `folder_path` (excluding *.mask.png files).\n",
    "    \n",
    "    Splits data by original_id (to avoid data leakage) into\n",
    "    80% train, 10% test, 10% val.\n",
    "    \n",
    "    NOTE: The paths inside train.txt/test.txt/val.txt will be relative\n",
    "    to `folder_path`.\n",
    "    \"\"\"\n",
    "    dir_images = Path(folder_path).resolve()\n",
    "\n",
    "    image_paths = [\n",
    "        p for p in dir_images.glob(\"*.png\")\n",
    "        if not p.name.endswith(\".mask.png\")\n",
    "    ]\n",
    "\n",
    "    groups = defaultdict(list)\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        json_path = img_path.with_suffix(\".json\")\n",
    "        if not json_path.exists():\n",
    "            print(f\"No matching JSON for {img_path.name}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        original_id = data[\"sourceImage\"]\n",
    "        groups[original_id].append(img_path)\n",
    "\n",
    "    original_ids = list(groups.keys())\n",
    "    random.shuffle(original_ids)\n",
    "\n",
    "    n = len(original_ids)\n",
    "    train_end = int(0.80 * n)\n",
    "    test_end  = int(0.90 * n)\n",
    "\n",
    "    train_ids = original_ids[:train_end]\n",
    "    test_ids  = original_ids[train_end:test_end]\n",
    "    val_ids   = original_ids[test_end:]\n",
    "\n",
    "    train_paths = [img for oid in train_ids for img in groups[oid]]\n",
    "    test_paths  = [img for oid in test_ids for img in groups[oid]]\n",
    "    val_paths   = [img for oid in val_ids for img in groups[oid]]\n",
    "\n",
    "    # Helper function to write one relative path per line\n",
    "    def write_split(filename: Path, paths: list[Path]):\n",
    "        with filename.open(\"w\") as f:\n",
    "            for p in paths:\n",
    "                f.write(p.name + \"\\n\")\n",
    "\n",
    "\n",
    "    write_split(dir_images / \"train.txt\", train_paths)\n",
    "    write_split(dir_images / \"test.txt\", test_paths)\n",
    "    write_split(dir_images / \"val.txt\", val_paths)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "create_yolo_dataset(\"p_BaseImages\")\n",
    "create_yolo_dataset(\"p_VariantImages\")\n",
    "create_yolo_dataset(\"p_VariantImagesWithOcclusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb4bc28f-3544-4be3-afe9-5ffe70d72c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created symlinks in:\n",
      "  datasets/p_BaseImages/images/train, datasets/p_BaseImages/images/test, datasets/p_BaseImages/images/val\n",
      "  datasets/p_BaseImages/labels/train, datasets/p_BaseImages/labels/test, datasets/p_BaseImages/labels/val\n",
      "[INFO] Wrote dataset.yaml to /home/gustavo-depaula/SyntheticRunwayDataset/datasets/p_BaseImages/dataset.yaml\n",
      "[DONE] The dataset folder is ready at: /home/gustavo-depaula/SyntheticRunwayDataset/datasets/p_BaseImages\n",
      "[INFO] Created symlinks in:\n",
      "  datasets/p_VariantImages/images/train, datasets/p_VariantImages/images/test, datasets/p_VariantImages/images/val\n",
      "  datasets/p_VariantImages/labels/train, datasets/p_VariantImages/labels/test, datasets/p_VariantImages/labels/val\n",
      "[INFO] Wrote dataset.yaml to /home/gustavo-depaula/SyntheticRunwayDataset/datasets/p_VariantImages/dataset.yaml\n",
      "[DONE] The dataset folder is ready at: /home/gustavo-depaula/SyntheticRunwayDataset/datasets/p_VariantImages\n",
      "[INFO] Created symlinks in:\n",
      "  datasets/p_VariantImagesWithOcclusion/images/train, datasets/p_VariantImagesWithOcclusion/images/test, datasets/p_VariantImagesWithOcclusion/images/val\n",
      "  datasets/p_VariantImagesWithOcclusion/labels/train, datasets/p_VariantImagesWithOcclusion/labels/test, datasets/p_VariantImagesWithOcclusion/labels/val\n",
      "[INFO] Wrote dataset.yaml to /home/gustavo-depaula/SyntheticRunwayDataset/datasets/p_VariantImagesWithOcclusion/dataset.yaml\n",
      "[DONE] The dataset folder is ready at: /home/gustavo-depaula/SyntheticRunwayDataset/datasets/p_VariantImagesWithOcclusion\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def process_folder_structure_with_labels(folder_path: str):\n",
    "    \"\"\"\n",
    "    Reads train.txt, test.txt, val.txt from `folder_path` (which was created by create_yolo_dataset).\n",
    "    Builds a YOLO directory structure in `datasets/<folder_name>`, placing:\n",
    "    \n",
    "      datasets/<folder_name>/\n",
    "        images/train/ -> symlinks to the train images\n",
    "        images/test/  -> symlinks to the test images\n",
    "        images/val/   -> symlinks to the val images\n",
    "        labels/train/ -> symlinks to the corresponding train labels\n",
    "        labels/test/  -> symlinks to the corresponding test labels\n",
    "        labels/val/   -> symlinks to the corresponding val labels\n",
    "        dataset.yaml  -> references these subfolders\n",
    "\n",
    "    :param folder_path: The path to your original folder (e.g. \"p_BaseImages\"),\n",
    "                        which must have train.txt, test.txt, val.txt, dataset.yaml\n",
    "                        already generated by create_yolo_dataset().\n",
    "    \"\"\"\n",
    "\n",
    "    src_dir = Path(folder_path).resolve()\n",
    "    folder_name = src_dir.name  # e.g. \"p_BaseImages\"\n",
    "\n",
    "    # The new dataset directory, e.g. datasets/p_BaseImages\n",
    "    dst_base = Path(\"datasets\") / folder_name\n",
    "    dst_base.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # keep the standard YOLO layout:\n",
    "    # images/train, images/test, images/val, plus labels/train, labels/test, labels/val\n",
    "    images_dir = dst_base / \"images\"\n",
    "    labels_dir = dst_base / \"labels\"\n",
    "    train_img_dir = images_dir / \"train\"\n",
    "    test_img_dir  = images_dir / \"test\"\n",
    "    val_img_dir   = images_dir / \"val\"\n",
    "    train_lbl_dir = labels_dir / \"train\"\n",
    "    test_lbl_dir  = labels_dir / \"test\"\n",
    "    val_lbl_dir   = labels_dir / \"val\"\n",
    "\n",
    "    train_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "    test_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "    val_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "    train_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
    "    test_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
    "    val_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_file = src_dir / \"train.txt\"\n",
    "    test_file  = src_dir / \"test.txt\"\n",
    "    val_file   = src_dir / \"val.txt\"\n",
    "\n",
    "    for required_file in [train_file, test_file, val_file]:\n",
    "        if not required_file.exists():\n",
    "            print(f\"[ERROR] {required_file} does not exist. \"\n",
    "                  \"Did you run create_yolo_dataset first?\")\n",
    "            return\n",
    "\n",
    "    def symlink_split(txt_file: Path, dst_img_dir: Path, dst_lbl_dir: Path):\n",
    "        \"\"\"\n",
    "        For each filename in txt_file (one per line), create a symlink in dst_img_dir for the image,\n",
    "        and a symlink in dst_lbl_dir for the label (same base name, .txt).\n",
    "        \"\"\"\n",
    "        with txt_file.open(\"r\") as f:\n",
    "            lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "        for filename in lines:\n",
    "            # The original image file in src_dir\n",
    "            src_img = src_dir / filename  # e.g. p_BaseImages/image001.png\n",
    "            if not src_img.exists():\n",
    "                print(f\"[WARNING] Image file not found: {src_img}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            # The corresponding label (same base name with .txt)\n",
    "            # e.g. p_BaseImages/image001.txt\n",
    "            src_lbl = src_img.with_suffix(\".txt\")\n",
    "\n",
    "            if not src_lbl.exists():\n",
    "                print(f\"[WARNING] Label not found for {src_img.name}, expected {src_lbl.name}, skipping label symlink.\")\n",
    "\n",
    "            # symlinks:\n",
    "            dst_img_link = dst_img_dir / src_img.name\n",
    "            dst_lbl_link = dst_lbl_dir / src_lbl.name\n",
    "\n",
    "            if dst_img_link.exists():\n",
    "                dst_img_link.unlink()\n",
    "            if dst_lbl_link.exists():\n",
    "                dst_lbl_link.unlink()\n",
    "\n",
    "            os.symlink(src_img, dst_img_link)\n",
    "\n",
    "            if src_lbl.exists():\n",
    "                os.symlink(src_lbl, dst_lbl_link)\n",
    "\n",
    "    # Symlink the train, test, val sets\n",
    "    symlink_split(train_file, train_img_dir, train_lbl_dir)\n",
    "    symlink_split(test_file,  test_img_dir,  test_lbl_dir)\n",
    "    symlink_split(val_file,   val_img_dir,   val_lbl_dir)\n",
    "\n",
    "    print(f\"[INFO] Created symlinks in:\")\n",
    "    print(f\"  {train_img_dir}, {test_img_dir}, {val_img_dir}\")\n",
    "    print(f\"  {train_lbl_dir}, {test_lbl_dir}, {val_lbl_dir}\")\n",
    "\n",
    "    # Create (or overwrite) dataset.yaml referencing these subfolders\n",
    "    dataset_yaml_content = f\"\"\"# YOLO dataset config\n",
    "# Automatically generated for {folder_name}\n",
    "\n",
    "path: {folder_name}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "names:\n",
    "  0: runway\n",
    "\"\"\"\n",
    "\n",
    "    dst_dataset_yaml = dst_base / \"dataset.yaml\"\n",
    "    with dst_dataset_yaml.open(\"w\") as f:\n",
    "        f.write(dataset_yaml_content)\n",
    "\n",
    "    print(f\"[INFO] Wrote dataset.yaml to {dst_dataset_yaml.resolve()}\")\n",
    "    print(f\"[DONE] The dataset folder is ready at: {dst_base.resolve()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d08bf1-41a7-4255-95d0-e64168eb20eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_folder_structure_with_labels(\"p_BaseImages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0609066c-a1d1-46b5-83ed-766d4665c17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created symlinks in:\n",
      "  datasets/p_VariantImages/images/train, datasets/p_VariantImages/images/test, datasets/p_VariantImages/images/val\n",
      "  datasets/p_VariantImages/labels/train, datasets/p_VariantImages/labels/test, datasets/p_VariantImages/labels/val\n",
      "[INFO] Wrote dataset.yaml to /home/gustavo-depaula/SyntheticRunwayDataset/datasets/p_VariantImages/dataset.yaml\n",
      "[DONE] The dataset folder is ready at: /home/gustavo-depaula/SyntheticRunwayDataset/datasets/p_VariantImages\n",
      "[INFO] Created symlinks in:\n",
      "  datasets/p_VariantImagesWithOcclusion/images/train, datasets/p_VariantImagesWithOcclusion/images/test, datasets/p_VariantImagesWithOcclusion/images/val\n",
      "  datasets/p_VariantImagesWithOcclusion/labels/train, datasets/p_VariantImagesWithOcclusion/labels/test, datasets/p_VariantImagesWithOcclusion/labels/val\n",
      "[INFO] Wrote dataset.yaml to /home/gustavo-depaula/SyntheticRunwayDataset/datasets/p_VariantImagesWithOcclusion/dataset.yaml\n",
      "[DONE] The dataset folder is ready at: /home/gustavo-depaula/SyntheticRunwayDataset/datasets/p_VariantImagesWithOcclusion\n"
     ]
    }
   ],
   "source": [
    "process_folder_structure_with_labels(\"p_VariantImages\")\n",
    "process_folder_structure_with_labels(\"p_VariantImagesWithOcclusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ab7293-0847-4212-a970-9dc65b908b41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
