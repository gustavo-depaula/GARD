\chapter{Conclusion}

To address the challenges of data scarcity in the field of runway detection and segmentation,
this paper introduced a novel, open-source data augmentation technique based on a multi-step
Stable Diffusion pipeline, called \emph{Canny2Concrete}.

\emph{Canny2Concrete} extracts features from existing datasets and outputs images
that retain a similar structure, especially the runway shape, position, and markings, but are
customizable with respect to scenery, weather, and lighting conditions, guided by
text prompts. The images generated by the pipeline are already
labeled, saving hours of manual labeling.

\emph{Canny2Concrete} is a modular and easily extensible pipeline, composed of four
independent modules: Template Image Selection, Edge Extraction, Base Image Generation,
and Variant Image Generation. This design facilitates rapid development and
allows easy adaptation to other domains beyond runway imagery.

The pipeline is tested by augmenting real runway images from the LARD \cite{ducoffe_lard_2023}
dataset, generating \ac{GARD}. Three datasets are generated: the Base Images dataset,
containing 6498 images; the Variant Images dataset, containing 19494 images; and
the Variant Images With Occlusion dataset, containing 19494 images. In total,
45486 images, with a diverse range of weather, lighting, background, and runway
occlusion conditions and effects were generated and are publicly available on Kaggle.
To the best of my knowledge, \emph{GARD} is the largest synthetic runway
dataset publicly available.

All the images have a JSON file
with metadata allowing any researcher to replicate that exact image, a TXT label
ready to be used in training YOLO models, and a simple binary segmentation mask
image. 

Experimental evaluation was done by training state-of-the-art detection and
segmentation models with both the new datasets and a benchmark dataset, and
these models were evaluated on a real-world dataset. The results demonstrate
the effectiveness of the \emph{Canny2Concrete} pipeline in generating realistic runway
images, and the viability of diffusion-based augmentation for runway segmentation
tasks.

In summary, this work directly addresses the research question posed at the
outsetâ€”how to build a suitable synthetic image dataset without using simulators.
By leveraging a novel and modular image generation pipeline using edge
detection, latent diffusion models, and image augmentation techniques, this work
demonstrates a practical and reproducible method for generating high-quality,
labeled runway images at scale. \ac{GARD}, the resulting dataset, not only bypasses the need
for flight simulators but also achieves competitive quality, realism, and utility for
training object detection and segmentation models, as evidenced by performance
benchmarks.

