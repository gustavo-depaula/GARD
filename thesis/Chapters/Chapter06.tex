\chapter{Conclusion}

To address the challenges of data scarcity in the field of runway detection and segmentation,
this paper introduced a novel, open-source, data augmentation technique based on a multi-step
Stable Diffusion pipeline, called Canny2Concrete.

Canny2Concrete extracts features from existing datasets and outputs images
that retain a similar structure, especially the runway shape, position, and markings, but are
customizable in respect to scenery, weather, and lighting conditions, guided by
a text prompts. The images generated by the pipeline are already
labeled, saving hours of handcraft labelling.

- falar que o Canny2Concrete pode ser usado em outros campos/ adaptado para
- falar o nome do GARD

The pipeline is tested by augmenting real runway images from the LARD \cite{ducoffe_lard_2023}
dataset. Three datasets are generated, the Base Images dataset,
containing 6498 images, the Variant Images dataset, containing 19494 images, and
the Variant Images With Occlusion dataset, containing 19494 images. In total,
45486 images, with a diverse range of weather, lighting, background, and runway
occlusion conditions and effects were generated and are publicly on Kaggle.

All the images have along with
them a JSON file
with metadata allowing any researcher to replicate that exact image, TXT label
ready to be used in training YOLO models, and a simple binary segmentation mask
image. To the best of my knowledge, \emph{GARD} is the largest synthetic runway
dataset publicly available.

Experimental evaluation was done training state-of-the-art detection and
segmentation models with both the new datasets and a benchmark dataset, and
these models were evaluated on a real-world dataset. The results demonstrate
the effectiveness of the Canny2Concrete pipeline in generating realistic runway
images, and the viability of diffusion-based augmentation for runway segmentation
tasks.

\section{Further Work}
